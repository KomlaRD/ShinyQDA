% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/irr.R
\name{irr}
\alias{irr}
\title{Calculate inter-rater reliability statistics}
\usage{
irr(qda_data, min_ratings = 5, coders)
}
\arguments{
\item{qda_data}{a \code{qda} object.}

\item{min_ratings}{the minimal number of text documents that are double coded
for the IRR statistics to be calculated.}

\item{coders}{a character vector of coders to include in the IRR calculations.
If omitted then all coders will be used.}
}
\value{
a data.frame with inter-rater reliability (IRR) statistics for each code
(see \code{qda_data$get_codes()}) and pair of coders.
}
\description{
This function will calculate inter-rater reliability statistics for each code.
The resulting data.frame will have the following columns:
}
\details{
\itemize{
\item \code{code} - the code.
\item \code{n_text} - the number of text documents with at least two coders.
\item \code{n_codes} - the total number of times this code has been used.
\item \code{n_text_with_code} - the number of text documents with this code.
\item \code{pra} - Exact percent rater agreement. This compares the number of times
the code was used for each text document.
\item \code{icc1}, \code{icc2}, \code{icc3}, \code{icc1k}, \code{icc2k}, \code{icc3k} - Intraclass correlation
coefficient. See \link[psych:ICC]{psych::ICC} for more details.
}
}
